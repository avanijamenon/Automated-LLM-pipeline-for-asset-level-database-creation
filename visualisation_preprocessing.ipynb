{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0be8c0c1-c28d-47db-9f32-8ee946b1a0fa",
   "metadata": {},
   "source": [
    "## AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95b5247-058e-42d9-8e39-efa3da0c0180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_18596\\1640045971.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_spaces_around_commas(cell_value):\n",
    "    if isinstance(cell_value, str):\n",
    "        return ','.join(item.strip() for item in cell_value.split(','))\n",
    "    return cell_value\n",
    "\n",
    "def process_csv_file(input_file, output_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df = df.applymap(remove_spaces_around_commas)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\AA_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\AA_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbda29ee-f487-4b03-88ad-0463e0fb4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "def split_rows(df):\n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',')).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded\n",
    "    \n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\AA_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab862380-034d-40f7-83b9-66ab05b5312d",
   "metadata": {},
   "source": [
    "## FCX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b18b10-e80c-46f1-aa4d-d542a616a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_5132\\2963933793.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\FCX\\FCX_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\FCX\\FCX_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bf991c-3eb4-4b35-87d1-26802288a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\FCX\\FCX_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\FCX\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2ac39-04e3-4261-b0f1-7d413370f4cd",
   "metadata": {},
   "source": [
    "## HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf15854-623a-4454-8e59-500d91652c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_5132\\1060163975.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\HL_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\HL_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "    \n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\HL_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a2040-54f5-431e-ba7b-a1f67646cfc2",
   "metadata": {},
   "source": [
    "## NEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bcca66-e4ea-4703-8f41-cca3337b0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_5132\\1224446519.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\NEM_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\NEM_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "    \n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\NEM_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbfa011-87cb-4407-ae6a-0c6879631d7d",
   "metadata": {},
   "source": [
    "## SCCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f321614d-a601-4148-a890-9107c970548b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_23072\\1736528545.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\SCCO\\SCCO_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\SCCO\\SCCO_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5125b2e2-2e8c-44cc-b0f2-2fa22aa1f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\SCCO\\SCCO_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\SCCO\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb90f48-7a12-4fb2-9080-28e40c9fc1d1",
   "metadata": {},
   "source": [
    "# COP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60296f1b-485a-49e4-a28a-b709a836bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_14900\\516354221.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\COP\\COP_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\COP\\COP_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547c2f6d-7619-4482-a982-233b9f1a7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\COP\\COP_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\COP\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc488c0-87bb-4be3-958b-9b3783a1100c",
   "metadata": {},
   "source": [
    "# CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca67ec96-d178-480c-bc9d-1367e531b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           physical asset  \\\n",
      "0  Upstream Property, Plant And Equipment   \n",
      "1                                 Acreage   \n",
      "2                     C3 Splitter Project   \n",
      "3                         Chemical Plants   \n",
      "4                  Facilities (Chemicals)   \n",
      "\n",
      "                                            location  \\\n",
      "0  USA, Australia, International, California, Den...   \n",
      "1                                             Africa   \n",
      "2                                 Cedar Bayou, Texas   \n",
      "3                                      International   \n",
      "4  Permian Basin, USA, North America, California,...   \n",
      "\n",
      "                                           ownership  \\\n",
      "0  Chevron Corporation, Chevron Phillips Chemical...   \n",
      "1                                                NaN   \n",
      "2              Chevron Phillips Chemical Company LLC   \n",
      "3                                Chevron Corporation   \n",
      "4  Chevron Corporation, Third-Party, Affiliates, TCF   \n",
      "\n",
      "                                           commodity  \\\n",
      "0      Crude Oil, Natural Gas, Petroleum, Chemicals    \n",
      "1                                        Natural Gas   \n",
      "2                                                NaN   \n",
      "3                                          Chemicals   \n",
      "4  Crude Oil, Natural Gas, Petroleum Products, Pe...   \n",
      "\n",
      "                                           Countries status  \\\n",
      "0                                     USA, Australia    NaN   \n",
      "1                                                NaN    NaN   \n",
      "2                                                USA    NaN   \n",
      "3                                                NaN    NaN   \n",
      "4  USA, Canada, Colombia, Angola, Australia, Kaza...    NaN   \n",
      "\n",
      "             USA states  \n",
      "0  California, Delaware  \n",
      "1                  None  \n",
      "2                 Texas  \n",
      "3                  None  \n",
      "4  California, Delaware  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\CVX_w_table_coverage.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# List of US states\n",
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Function to extract US states from the location column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = [state for state in us_states if state in location]\n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the location column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\CVX_w_states.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2eebf-9388-44b4-990f-a77109db642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces_around_commas(cell_value):\n",
    "    if isinstance(cell_value, str):\n",
    "        return ','.join(item.strip() for item in cell_value.split(','))\n",
    "    return cell_value\n",
    "\n",
    "def process_csv_file(input_file, output_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df = df.applymap(remove_spaces_around_commas)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\CVX_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\CVX_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "\n",
    "def split_rows(df):\n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',')).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e04d1da-4744-41fa-8bac-90b63c00d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\CVX_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\CVX\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a98506-713e-4868-846d-cb3a6556c3db",
   "metadata": {},
   "source": [
    "# MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55110e4-b851-4df0-b843-e5271daeafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_13916\\620914862.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\MPC\\MPC_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\MPC\\MPC_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)\n",
    "\n",
    "def split_rows(df):\n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',')).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7504e4-3f4f-4b73-8720-7ad4e13a58b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\MPC\\MPC_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\MPC\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef0e46-a247-44e5-9da8-b34518361c5e",
   "metadata": {},
   "source": [
    "# OXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1e55d4-a9b7-4065-8a52-791da7bf2e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_13916\\1932675887.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\OXY\\OXY_w_states.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\OXY\\OXY_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f3ffbf-6e5a-474a-83e9-018dd20c96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\OXY\\OXY_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\OXY\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb09a6-50e3-4281-b3f6-59a6beec5d13",
   "metadata": {},
   "source": [
    "# XOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf47d20-94fc-43fb-a51f-ac7617a2c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               physical asset  \\\n",
      "0                            Acreage Holdings   \n",
      "1  Additions To Property, Plant And Equipment   \n",
      "2                                    Bitumen    \n",
      "3                                  Facilities   \n",
      "4                          Chemical Products    \n",
      "\n",
      "                                            location  \\\n",
      "0  USA, Canada, Other Americas, Europe, Africa, A...   \n",
      "1  USA, Canada, Singapore, United Kingdom, France...   \n",
      "2                                             Europe   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                           ownership  \\\n",
      "0                              ExxonMobil,Government   \n",
      "1       ExxonMobil,Pioneer Natural Resources Company   \n",
      "2  Equity Companies,Consolidated Subsidiaries,Exx...   \n",
      "3                                         ExxonMobil   \n",
      "4                                         ExxonMobil   \n",
      "\n",
      "                                   commodity  \\\n",
      "0                            Oil,Natural Gas   \n",
      "1  Crude oil, Natural Gas, Refinery Products   \n",
      "2                      Bitumen,Synthetic oil   \n",
      "3                           Oil, Natural Gas   \n",
      "4                                        NaN   \n",
      "\n",
      "                                           Countries  status USA states  \n",
      "0                        USA, Canada, United Kingdom     NaN       None  \n",
      "1  USA, Canada, Singapore, United Kingdom, France...     NaN       None  \n",
      "2                                             Europe     NaN       None  \n",
      "3                                                NaN     NaN       None  \n",
      "4                                                NaN     NaN       None  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\XOM_w_table_coverage.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# List of US states\n",
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Function to extract US states from the location column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = [state for state in us_states if state in location]\n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the location column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\XOM_w_states_final.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55c5733-9cdd-4e88-ab37-b517695e6d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_13916\\232419171.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_spaces_around_commas)\n"
     ]
    }
   ],
   "source": [
    "input_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\XOM_w_states_final.csv'\n",
    "output_file = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\XOM_FINAL.csv'\n",
    "process_csv_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f7beb1f-68bb-4a38-86b4-405ad2717403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\XOM_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\oilandgas\\XOM\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Define the function to split rows\n",
    "def split_rows(df):\n",
    "    for column in ['physical asset', 'ownership', 'commodity', 'Countries']:\n",
    "        df[column] = df[column].astype(str).str.split(',')\n",
    "    df_expanded = df.explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32819d9-b200-4327-83b9-10e5734a182b",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163431c5-5430-4b98-9a7a-a63a801811df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      physical asset  \\\n",
      "0          Acquisition Of Solar Development Projects   \n",
      "1                                          Ash Ponds   \n",
      "2                            Atlantic Coast Pipeline   \n",
      "3                             Battery Energy Systems   \n",
      "4  brunswick county a, mw combined-cycle power pl...   \n",
      "\n",
      "                                            location  \\\n",
      "0  Virginia, Ohio, South Carolina, North Carolina...   \n",
      "1                                           Virginia   \n",
      "2            West Virginia, Virginia, North Carolina   \n",
      "3                        Virginia, Various Locations   \n",
      "4          Brunswick County, Virginia, Warren County   \n",
      "\n",
      "                                        ownership                commodity  \\\n",
      "0                Dominion Energy , Virginia Power  Electricity,Solar Power   \n",
      "1                Dominion Energy , Virginia Power                     Coal   \n",
      "2  Dominion Energy, Duke Energy, Southern Company          Natural Gas,Oil   \n",
      "3                                  Virginia Power       Energy,Electricity   \n",
      "4          Dominion Energy, Virginia Power, SCANA              Electricity   \n",
      "\n",
      "  Countries  status Country                                         USA states  \n",
      "0       USA     NaN     NaN  Ohio, Texas, Pennsylvania, Virginia, South Car...  \n",
      "1       USA     NaN     NaN                                           Virginia  \n",
      "2       USA     NaN     NaN            West Virginia, Virginia, North Carolina  \n",
      "3       USA     NaN     NaN                                           Virginia  \n",
      "4       USA     NaN     NaN                                           Virginia  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\D_FINAL.csv' \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Dictionary of US states and their abbreviations\n",
    "us_states_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Function to extract US states from the physical asset column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = set()\n",
    "    \n",
    "    # Check for full state names\n",
    "    for state in us_states_abbrev.keys():\n",
    "        if state in location:\n",
    "            found_states.add(state)\n",
    "    \n",
    "    # Check for state abbreviations\n",
    "    for abbrev in abbrev_to_state.keys():\n",
    "        if abbrev in location:\n",
    "            found_states.add(abbrev_to_state[abbrev])\n",
    "    \n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\D_FINAL_NEW.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c51ea4d-da2b-4443-b842-1df99769d82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_3420\\3967803960.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(remove_spaces_around_comma)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\D_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Function to remove spaces before or after a comma\n",
    "def remove_spaces_around_comma(text):\n",
    "    if isinstance(text, str):\n",
    "        return ','.join([part.strip() for part in text.split(',')])\n",
    "    return text\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to remove spaces around commas for all string entries\n",
    "data = data.applymap(remove_spaces_around_comma)\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4db845-95f1-4bd2-9a63-f1bf5122c529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              physical asset  \\\n",
      "0  Acquisition Of Solar Development Projects   \n",
      "1  Acquisition Of Solar Development Projects   \n",
      "2  Acquisition Of Solar Development Projects   \n",
      "3  Acquisition Of Solar Development Projects   \n",
      "4                                  Ash Ponds   \n",
      "\n",
      "                                            location        ownership  \\\n",
      "0  Virginia,Ohio,South Carolina,North Carolina,Te...  Dominion Energy   \n",
      "1  Virginia,Ohio,South Carolina,North Carolina,Te...  Dominion Energy   \n",
      "2  Virginia,Ohio,South Carolina,North Carolina,Te...   Virginia Power   \n",
      "3  Virginia,Ohio,South Carolina,North Carolina,Te...   Virginia Power   \n",
      "4                                           Virginia  Dominion Energy   \n",
      "\n",
      "     commodity Countries  status Country  \\\n",
      "0  Electricity       USA     NaN     NaN   \n",
      "1  Solar Power       USA     NaN     NaN   \n",
      "2  Electricity       USA     NaN     NaN   \n",
      "3  Solar Power       USA     NaN     NaN   \n",
      "4         Coal       USA     NaN     NaN   \n",
      "\n",
      "                                          USA states  \n",
      "0  Ohio, Texas, Pennsylvania, Virginia, South Car...  \n",
      "1  Ohio, Texas, Pennsylvania, Virginia, South Car...  \n",
      "2  Ohio, Texas, Pennsylvania, Virginia, South Car...  \n",
      "3  Ohio, Texas, Pennsylvania, Virginia, South Car...  \n",
      "4                                           Virginia  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\visualisation_preprocessed.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Dictionary of US states and their abbreviations\n",
    "us_states_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Function to extract US states from the physical asset column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = set()\n",
    "    \n",
    "    # Check for full state names\n",
    "    for state in us_states_abbrev.keys():\n",
    "        if state in location:\n",
    "            found_states.add(state)\n",
    "    \n",
    "    # Check for state abbreviations\n",
    "    for abbrev in abbrev_to_state.keys():\n",
    "        if abbrev in location:\n",
    "            found_states.add(abbrev_to_state[abbrev])\n",
    "    \n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\D\\visualisation_preprocessed_new.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d0c8d-5709-40ab-8252-e87ed3837bcf",
   "metadata": {},
   "source": [
    "# DUK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28bc04e1-c289-432e-b5c8-fdaef780ecad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               physical asset  \\\n",
      "0    Storm Recovery Property    \n",
      "1            Abandoned Plants   \n",
      "2            Ash Impoundments   \n",
      "3     Atlantic Coast Pipeline   \n",
      "4  Buildings And Improvements   \n",
      "\n",
      "                                            location  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2  Duke Energy Carolinas, Duke Energy Progress, V...   \n",
      "3                      West Virginia, North Carolina   \n",
      "4                                                NaN   \n",
      "\n",
      "                                           ownership  \\\n",
      "0  Duke Energy Carolinas, Duke Energy Progress, D...   \n",
      "1                                        Duke Energy   \n",
      "2  Duke Energy, Duke Energy Carolinas, Duke Energ...   \n",
      "3                        Atlantic Coast Pipeline LLC   \n",
      "4                                        Duke Energy   \n",
      "\n",
      "                                           commodity Countries  status  \\\n",
      "0                                        Electricity       NaN     NaN   \n",
      "1                                                NaN       NaN     NaN   \n",
      "2  Electricity, Coal Combustion Byproduct, Waste ...       USA     NaN   \n",
      "3                                        Natural Gas       USA     NaN   \n",
      "4                                                NaN       NaN     NaN   \n",
      "\n",
      "                                USA states  \n",
      "0                                     None  \n",
      "1                                     None  \n",
      "2  Florida, North Carolina, South Carolina  \n",
      "3  North Carolina, Virginia, West Virginia  \n",
      "4                                     None  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_w_table_coverage.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# List of US states\n",
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Function to extract US states from the location column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = [state for state in us_states if state in location]\n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the location column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_FINAL.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f375af-5a5a-48a9-899a-c7e3e361cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_3388\\3671841661.py:28: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(remove_spaces_around_comma)\n"
     ]
    }
   ],
   "source": [
    "def split_rows(df):\n",
    "    # Ensure that the columns to be split are strings\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != 'object':  # 'object' dtype in pandas is typically for strings\n",
    "            continue\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',') if x.dtype == 'object' else x).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded\n",
    "\n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_visualisation_preprocessed.csv'\n",
    "\n",
    "# Function to remove spaces before or after a comma\n",
    "def remove_spaces_around_comma(text):\n",
    "    if isinstance(text, str):\n",
    "        return ','.join([part.strip() for part in text.split(',')])\n",
    "    return text\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to remove spaces around commas for all string entries\n",
    "data = data.applymap(remove_spaces_around_comma)\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eab5bbb-2e37-4062-ade0-01af1956a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               physical asset  \\\n",
      "0    Storm Recovery Property    \n",
      "1            Abandoned Plants   \n",
      "2            Ash Impoundments   \n",
      "3     Atlantic Coast Pipeline   \n",
      "4  Buildings And Improvements   \n",
      "\n",
      "                                            location  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2  Duke Energy Carolinas, Duke Energy Progress, V...   \n",
      "3                      West Virginia, North Carolina   \n",
      "4                                                NaN   \n",
      "\n",
      "                                           ownership  \\\n",
      "0  Duke Energy Carolinas, Duke Energy Progress, D...   \n",
      "1                                        Duke Energy   \n",
      "2  Duke Energy, Duke Energy Carolinas, Duke Energ...   \n",
      "3                        Atlantic Coast Pipeline LLC   \n",
      "4                                        Duke Energy   \n",
      "\n",
      "                                           commodity Countries  status  \\\n",
      "0                                        Electricity       NaN     NaN   \n",
      "1                                                NaN       NaN     NaN   \n",
      "2  Electricity, Coal Combustion Byproduct, Waste ...       USA     NaN   \n",
      "3                                        Natural Gas       USA     NaN   \n",
      "4                                                NaN       NaN     NaN   \n",
      "\n",
      "                                USA states  \n",
      "0                                     None  \n",
      "1                                     None  \n",
      "2  North Carolina, South Carolina, Florida  \n",
      "3  Virginia, North Carolina, West Virginia  \n",
      "4                                     None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_FINAL.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Dictionary of US states and their abbreviations\n",
    "us_states_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Function to extract US states from the physical asset column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = set()\n",
    "    \n",
    "    # Check for full state names\n",
    "    for state in us_states_abbrev.keys():\n",
    "        if state in location:\n",
    "            found_states.add(state)\n",
    "    \n",
    "    # Check for state abbreviations\n",
    "    for abbrev in abbrev_to_state.keys():\n",
    "        if abbrev in location:\n",
    "            found_states.add(abbrev_to_state[abbrev])\n",
    "    \n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\DUK_FINAL_new.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440ab97-9bc6-4a68-ab5f-1012db2e7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\visualisation_preprocessed.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Dictionary of US states and their abbreviations\n",
    "us_states_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Function to extract US states from the physical asset column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = set()\n",
    "    \n",
    "    # Check for full state names\n",
    "    for state in us_states_abbrev.keys():\n",
    "        if state in location:\n",
    "            found_states.add(state)\n",
    "    \n",
    "    # Check for state abbreviations\n",
    "    for abbrev in abbrev_to_state.keys():\n",
    "        if abbrev in location:\n",
    "            found_states.add(abbrev_to_state[abbrev])\n",
    "    \n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\DUK\\visualisation_preprocessed_new.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ad62f-f0ec-43f8-82b3-7ee0f091605d",
   "metadata": {},
   "source": [
    "# ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6998e3-4b0d-44bd-b963-6a3371390c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_23072\\3987156137.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(remove_spaces_around_comma)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\ED\\ED_w_states.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\ED\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Function to remove spaces before or after a comma\n",
    "def remove_spaces_around_comma(text):\n",
    "    if isinstance(text, str):\n",
    "        return ','.join([part.strip() for part in text.split(',')])\n",
    "    return text\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to remove spaces around commas for all string entries\n",
    "data = data.applymap(remove_spaces_around_comma)\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b7b0e-eef7-4c67-9b53-887f72627f70",
   "metadata": {},
   "source": [
    "# EXC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c65f0ae-5de3-42e2-827c-f756e4bf6d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              physical asset  \\\n",
      "0  500kV Lines (Transmission Infrastructure)   \n",
      "1       Albany Green Energy Biomass Facility   \n",
      "2              Baltimore City Conduit System   \n",
      "3                          Benning Road Site   \n",
      "4       (Baltimore Gas And Electric Company)   \n",
      "\n",
      "                             location  \\\n",
      "0          New Jersey; Delaware River   \n",
      "1                         New England   \n",
      "2                      Baltimore City   \n",
      "3       Benning Road, Washington D.C.   \n",
      "4  Baltimore Gas And Electric Company   \n",
      "\n",
      "                                           ownership       commodity  \\\n",
      "0  PECO Energy Company, Pepco Holdings LLC, Delma...             NaN   \n",
      "1                                 Exelon Corporation  Biomass Energy   \n",
      "2                                                NaN             NaN   \n",
      "3             Exelon Corporation, Pepco Holdings LLC     Electricity   \n",
      "4                                 Exelon Corporation             NaN   \n",
      "\n",
      "  Countries            USA states  \n",
      "0       USA  Delaware, New Jersey  \n",
      "1       USA                  None  \n",
      "2       USA                  None  \n",
      "3       USA            Washington  \n",
      "4       USA                  None  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\EXC_w_table_coverage.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# List of US states\n",
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Function to extract US states from the location column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = [state for state in us_states if state in location]\n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the location column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\EXC_FINAL.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c24d692-c19b-46da-ba48-a9cf11316f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_13916\\4163398696.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(remove_spaces_around_comma)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\EXC_FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Function to remove spaces before or after a comma\n",
    "def remove_spaces_around_comma(text):\n",
    "    if isinstance(text, str):\n",
    "        return ','.join([part.strip() for part in text.split(',')])\n",
    "    return text\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to remove spaces around commas for all string entries\n",
    "data = data.applymap(remove_spaces_around_comma)\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d786da-56a5-401a-882c-7fc1d3029d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              physical asset  \\\n",
      "0  500kV Lines (Transmission Infrastructure)   \n",
      "1       Albany Green Energy Biomass Facility   \n",
      "2              Baltimore City Conduit System   \n",
      "3                          Benning Road Site   \n",
      "4       (Baltimore Gas And Electric Company)   \n",
      "\n",
      "                             location  \\\n",
      "0          New Jersey; Delaware River   \n",
      "1                         New England   \n",
      "2                      Baltimore City   \n",
      "3       Benning Road, Washington D.C.   \n",
      "4  Baltimore Gas And Electric Company   \n",
      "\n",
      "                                           ownership       commodity  \\\n",
      "0  PECO Energy Company, Pepco Holdings LLC, Delma...             NaN   \n",
      "1                                 Exelon Corporation  Biomass Energy   \n",
      "2                                                NaN             NaN   \n",
      "3             Exelon Corporation, Pepco Holdings LLC     Electricity   \n",
      "4                                 Exelon Corporation             NaN   \n",
      "\n",
      "  Countries            USA states  \n",
      "0       USA  Delaware, New Jersey  \n",
      "1       USA                  None  \n",
      "2       USA                  None  \n",
      "3       USA            Washington  \n",
      "4       USA                  None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\EXC_FINAL.csv'  \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Dictionary of US states and their abbreviations\n",
    "us_states_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Function to extract US states from the physical asset column\n",
    "def extract_us_states(location):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    found_states = set()\n",
    "    \n",
    "    # Check for full state names\n",
    "    for state in us_states_abbrev.keys():\n",
    "        if state in location:\n",
    "            found_states.add(state)\n",
    "    \n",
    "    # Check for state abbreviations\n",
    "    for abbrev in abbrev_to_state.keys():\n",
    "        if abbrev in location:\n",
    "            found_states.add(abbrev_to_state[abbrev])\n",
    "    \n",
    "    return ', '.join(found_states) if found_states else None\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\EXC_FINAL_new.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6bf09a-5e8d-434b-9f8b-d9c3ea88bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              physical asset                    location  \\\n",
      "0  500kV Lines (Transmission Infrastructure)  New Jersey; Delaware River   \n",
      "1  500kV Lines (Transmission Infrastructure)  New Jersey; Delaware River   \n",
      "2  500kV Lines (Transmission Infrastructure)  New Jersey; Delaware River   \n",
      "3  500kV Lines (Transmission Infrastructure)  New Jersey; Delaware River   \n",
      "4  500kV Lines (Transmission Infrastructure)  New Jersey; Delaware River   \n",
      "\n",
      "                        ownership commodity Countries            USA states  \n",
      "0             PECO Energy Company       NaN       USA  Delaware, New Jersey  \n",
      "1              Pepco Holdings LLC       NaN       USA  Delaware, New Jersey  \n",
      "2  Delmarva Power & Light Company       NaN       USA  Delaware, New Jersey  \n",
      "3  Atlantic City Electric Company       NaN       USA  Delaware, New Jersey  \n",
      "4              Exelon Corporation       NaN       USA  Delaware, New Jersey  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\visualisation_preprocessed.csv' \n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Reverse the dictionary for quick lookup from abbreviation to state name\n",
    "abbrev_to_state = {v: k for k, v in us_states_abbrev.items()}\n",
    "\n",
    "# Apply the function to the 'physical asset' column\n",
    "data['USA states'] = data['location'].apply(extract_us_states)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\EXC\\visualisation_preprocessed_new.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79863f7f-1c00-4bb3-b8d6-d2fc58a79fa8",
   "metadata": {},
   "source": [
    "# NEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18086515-a4bf-4be2-b32e-9ddf7d693ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploded file has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Local\\Temp\\ipykernel_13916\\3372243654.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(remove_spaces_around_comma)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\NEE\\NEE_w_states.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\utilities\\NEE\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Function to remove spaces before or after a comma\n",
    "def remove_spaces_around_comma(text):\n",
    "    if isinstance(text, str):\n",
    "        return ','.join([part.strip() for part in text.split(',')])\n",
    "    return text\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to remove spaces around commas for all string entries\n",
    "data = data.applymap(remove_spaces_around_comma)\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f6e974-6f17-4f6f-9804-53d0a9ece98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "def split_rows(df):\n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',')).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded\n",
    "    \n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\removedlocations.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7039ea96-a658-4af1-a9d7-0a504fa0cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_rows(df):\n",
    "    # Split each column by commas and explode the lists into separate rows\n",
    "    df_expanded = df.apply(lambda x: x.str.split(',')).explode('physical asset').explode('ownership').explode('commodity').explode('Countries')\n",
    "    return df_expanded\n",
    "    \n",
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\NEM\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e40ca3d-3336-486a-b900-815d6f3c115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded file has been saved\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\FINAL.csv'\n",
    "output_file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\AA\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(input_file_path, encoding='latin1')\n",
    "\n",
    "# Apply the function to split the rows\n",
    "data_expanded = split_rows(data)\n",
    "\n",
    "# Save the expanded dataframe to a new CSV file\n",
    "data_expanded.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('exploded file has been saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2838ea7-70db-48dc-b3f1-664c9bf09848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input the path to the CSV file\n",
    "file_path = r'C:\\Users\\avani\\Desktop\\Thesis\\mining\\HL\\visualisation_preprocessed.csv'\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Extract and clean ownership data\n",
    "data['ownership'] = data['ownership'].str.split(', ')\n",
    "all_ownerships = data.explode('ownership')['ownership']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
